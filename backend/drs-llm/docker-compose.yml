services:
  drs-seq-cls-api-test:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        UID: 23519
        GID: 6000
        USERNAME: app
    image: drs-llm-api:latest
    container_name: drs-cls-api-test
    working_dir: /workspace
    environment:
      - HOME=/workspace
      - NVIDIA_VISIBLE_DEVICES=2
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # --- App-specific overrides ---
      - HF_HOME=/workspace/.cache/seqcls/huggingface
      - CUDA_CACHE_PATH=/workspace/.cache/seqcls/nv
      - TORCHINDUCTOR_CACHE_DIR=/workspace/.cache/seqcls/torchinductor
      - PIP_CACHE_DIR=/workspace/.cache/seqcls/pip
      - PYTHONPYCACHEPREFIX=/workspace/.cache/seqcls/pyc

      - APP_MODULE=api_cls.app:app
      - PORT=8081
      - LOG_PREFIX=seq-cls
    volumes:
      - ./:/workspace
      - ../../../perf-pilot/LLMs:/LLMs:ro
    runtime: nvidia
    network_mode: host
    command: ["./run_with_logs.sh"]

  drs-clm-api:
    image: drs-llm-api:latest
    container_name: drs-clm-api-test
    working_dir: /workspace
    environment:
      - HOME=/workspace
      - NVIDIA_VISIBLE_DEVICES=3
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # --- App-specific overrides ---
      - HF_HOME=/workspace/.cache/clm/huggingface
      - CUDA_CACHE_PATH=/workspace/.cache/clm/nv
      - TORCHINDUCTOR_CACHE_DIR=/workspace/.cache/clm/torchinductor
      - PIP_CACHE_DIR=/workspace/.cache/clm/pip
      - PYTHONPYCACHEPREFIX=/workspace/.cache/clm/pyc

      - APP_MODULE=api_clm.app:app
      - PORT=8082
      - LOG_PREFIX=clm
      - DRSLLM_MODEL_ID=/LLMs/snapshots/meta-llama/Llama-3.1-8B
      # - DRSLLM_MAX_LENGTH=8000
    volumes:
      - ./:/workspace
      - ../../../perf-pilot/LLMs:/LLMs:ro
    runtime: nvidia
    network_mode: host
    command: ["./run_with_logs.sh"]
